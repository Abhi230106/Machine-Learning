{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9jmfcp9f8go",
        "outputId": "773da44b-e196-4760-99e0-01bdaf6c1a01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Sample 1 Original Code:\n",
            "\n",
            "def prime_factors(n):\n",
            "    factors = []\n",
            "    divisor = 2\n",
            "    while n > 1:\n",
            "        while n // divisor == 0:\n",
            "            factors.append(divisor)\n",
            "            n /= divisor\n",
            "        divisor += 2\n",
            "    return factors\n",
            "\n",
            "number = 56\n",
            "print(f\"Prime factors of {number} are: {prime_factors(number)}\")\n",
            "\n",
            "\n",
            " Number of Tokens: 136\n",
            " Tokens:\n",
            "['Ċ', 'def', 'Ġprime', '_', 'fact', 'ors', '(', 'n', '):', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġfactors', 'Ġ=', 'Ġ[]', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġdiv', 'is', 'or', 'Ġ=', 'Ġ2', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġwhile', 'Ġn', 'Ġ>', 'Ġ1', ':', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġwhile', 'Ġn', 'Ġ//', 'Ġdiv', 'is', 'or', 'Ġ==', 'Ġ0', ':', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġfactors', '.', 'append', '(', 'div', 'is', 'or', ')', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġn', 'Ġ/', '=', 'Ġdiv', 'is', 'or', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġdiv', 'is', 'or', 'Ġ+=', 'Ġ2', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġreturn', 'Ġfactors', 'Ċ', 'Ċ', 'number', 'Ġ=', 'Ġ56', 'Ċ', 'print', '(', 'f', '\"', 'Prime', 'Ġfactors', 'Ġof', 'Ġ{', 'number', '}', 'Ġare', ':', 'Ġ{', 'prime', '_', 'fact', 'ors', '(', 'number', ')}', '\")', 'Ċ']\n",
            "\n",
            " Token IDs:\n",
            "[50118, 9232, 2654, 1215, 24905, 994, 1640, 282, 3256, 50118, 1437, 1437, 1437, 2433, 5457, 48081, 50118, 1437, 1437, 1437, 14445, 354, 368, 5457, 132, 50118, 1437, 1437, 1437, 150, 295, 8061, 112, 35, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 150, 295, 21277, 14445, 354, 368, 45994, 321, 35, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 2433, 4, 48696, 1640, 26037, 354, 368, 43, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 295, 1589, 5214, 14445, 354, 368, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 14445, 354, 368, 49371, 132, 50118, 1437, 1437, 1437, 671, 2433, 50118, 50118, 30695, 5457, 4772, 50118, 17265, 1640, 506, 113, 25973, 2433, 9, 25522, 30695, 24303, 32, 35, 25522, 28752, 1215, 24905, 994, 1640, 30695, 48950, 8070, 50118]\n",
            "\n",
            " Sample 2 Original Code:\n",
            "\n",
            "def prime_factors(n):\n",
            "    factors = []\n",
            "    divisor = 2\n",
            "    while n > 1:\n",
            "        while n // divisor == 0:\n",
            "            factors.add(divisor)\n",
            "            n /= divisor\n",
            "        divisor += 2\n",
            "    return factors\n",
            "\n",
            "number = 56\n",
            "print(f\"Prime factors of {number} are: {prime_factors(number)}\")\n",
            "\n",
            "\n",
            " Number of Tokens: 136\n",
            " Tokens:\n",
            "['Ċ', 'def', 'Ġprime', '_', 'fact', 'ors', '(', 'n', '):', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġfactors', 'Ġ=', 'Ġ[]', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġdiv', 'is', 'or', 'Ġ=', 'Ġ2', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġwhile', 'Ġn', 'Ġ>', 'Ġ1', ':', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġwhile', 'Ġn', 'Ġ//', 'Ġdiv', 'is', 'or', 'Ġ==', 'Ġ0', ':', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġfactors', '.', 'add', '(', 'div', 'is', 'or', ')', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġn', 'Ġ/', '=', 'Ġdiv', 'is', 'or', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġdiv', 'is', 'or', 'Ġ+=', 'Ġ2', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġreturn', 'Ġfactors', 'Ċ', 'Ċ', 'number', 'Ġ=', 'Ġ56', 'Ċ', 'print', '(', 'f', '\"', 'Prime', 'Ġfactors', 'Ġof', 'Ġ{', 'number', '}', 'Ġare', ':', 'Ġ{', 'prime', '_', 'fact', 'ors', '(', 'number', ')}', '\")', 'Ċ']\n",
            "\n",
            " Token IDs:\n",
            "[50118, 9232, 2654, 1215, 24905, 994, 1640, 282, 3256, 50118, 1437, 1437, 1437, 2433, 5457, 48081, 50118, 1437, 1437, 1437, 14445, 354, 368, 5457, 132, 50118, 1437, 1437, 1437, 150, 295, 8061, 112, 35, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 150, 295, 21277, 14445, 354, 368, 45994, 321, 35, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 2433, 4, 4917, 1640, 26037, 354, 368, 43, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 295, 1589, 5214, 14445, 354, 368, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 14445, 354, 368, 49371, 132, 50118, 1437, 1437, 1437, 671, 2433, 50118, 50118, 30695, 5457, 4772, 50118, 17265, 1640, 506, 113, 25973, 2433, 9, 25522, 30695, 24303, 32, 35, 25522, 28752, 1215, 24905, 994, 1640, 30695, 48950, 8070, 50118]\n"
          ]
        }
      ],
      "source": [
        "from transformers import RobertaTokenizer\n",
        "import pandas as pd\n",
        "\n",
        "# Load CodeBERT tokenizer (same as RoBERTa-base for tokenization)\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "\n",
        "# Load sample code from Excel dataset\n",
        "df = pd.read_excel(\"/content/Regraded_Volunteering_Grader2.xlsx\")\n",
        "code_column = \"Code_with_Error\"  # Adjust if needed\n",
        "sample_codes = df[code_column].dropna().head(2).tolist()  # Get first 2 code samples\n",
        "\n",
        "# Tokenize and compare\n",
        "for i, code in enumerate(sample_codes):\n",
        "    print(f\"\\n Sample {i+1} Original Code:\\n{code}\\n\")\n",
        "\n",
        "    tokens = tokenizer.tokenize(code)\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "    print(f\" Number of Tokens: {len(tokens)}\")\n",
        "    print(\" Tokens:\")\n",
        "    print(tokens)\n",
        "    print(\"\\n Token IDs:\")\n",
        "    print(token_ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def chunk_code_by_lines(code, chunk_size):\n",
        "    \"\"\"Splits a block of code into chunks of max `chunk_size` lines.\"\"\"\n",
        "    if pd.isna(code): return []  # Handle NaN entries\n",
        "    lines = code.split('\\n')\n",
        "    return ['\\n'.join(lines[i:i+chunk_size]) for i in range(0, len(lines), chunk_size)]\n",
        "\n",
        "# Parameters\n",
        "file_path = '/content/Regraded_Volunteering_Grader2.xlsx'  # Update if needed\n",
        "code_column = 'Code_with_Error'                            # Update with actual code column name\n",
        "chunk_size = 4                                             # Lines per chunk\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Apply chunking\n",
        "chunked_data = []\n",
        "for idx, row in df.iterrows():\n",
        "    code_chunks = chunk_code_by_lines(row[code_column], chunk_size)\n",
        "    for i, chunk in enumerate(code_chunks):\n",
        "        chunked_data.append({\n",
        "            'original_index': idx,\n",
        "            'chunk_number': i,\n",
        "            'code_chunk': chunk\n",
        "        })\n",
        "\n",
        "# Create and save chunked DataFrame\n",
        "chunked_df = pd.DataFrame(chunked_data)\n",
        "chunked_df.to_csv('/content/chunked_code_dataset.csv', index=False)  # Save to desired path\n",
        "\n",
        "print(\" Chunked file saved as 'chunked_code_dataset.csv'\")\n",
        "print(chunked_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nebNtz7ixjB",
        "outputId": "e7d89cef-62a0-4ac7-f0d2-0aba051b2692"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Chunked file saved as 'chunked_code_dataset.csv'\n",
            "   original_index  chunk_number  \\\n",
            "0               0             0   \n",
            "1               0             1   \n",
            "2               0             2   \n",
            "3               0             3   \n",
            "4               1             0   \n",
            "\n",
            "                                          code_chunk  \n",
            "0  \\ndef prime_factors(n):\\n    factors = []\\n   ...  \n",
            "1      while n > 1:\\n        while n // divisor =...  \n",
            "2          divisor += 2\\n    return factors\\n\\nnu...  \n",
            "3  print(f\"Prime factors of {number} are: {prime_...  \n",
            "4  \\ndef prime_factors(n):\\n    factors = []\\n   ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/chunked_code_dataset.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "tqD17t6EkhxE",
        "outputId": "edab56e2-785d-44c3-f4b9-32f968e6dca7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_45e21ed9-458f-4323-b769-ce6df93cffce\", \"chunked_code_dataset.csv\", 521387)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizer\n",
        "import pandas as pd\n",
        "\n",
        "# Load CodeBERT tokenizer (same as RoBERTa-base for tokenization)\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "\n",
        "# Load sample code from Excel dataset\n",
        "df = pd.read_csv(\"/content/chunked_code_dataset.csv\")\n",
        "code_column = \"code_chunk\"  # Adjust if needed\n",
        "sample_codes = df[code_column].dropna().head(2).tolist()  # Get first 2 code samples\n",
        "\n",
        "# Tokenize and compare\n",
        "for i, code in enumerate(sample_codes):\n",
        "    print(f\"\\n Sample {i+1} Chunked Code:\\n{code}\\n\")\n",
        "\n",
        "    tokens = tokenizer.tokenize(code)\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "    print(f\" Number of Tokens: {len(tokens)}\")\n",
        "    print(\" Tokens:\")\n",
        "    print(tokens)\n",
        "    print(\"\\n Token IDs:\")\n",
        "    print(token_ids)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3-K2sgZgciS",
        "outputId": "a8d2d1af-8b01-4612-e92e-70dd56ab1904"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Sample 1 Chunked Code:\n",
            "\n",
            "def prime_factors(n):\n",
            "    factors = []\n",
            "    divisor = 2\n",
            "\n",
            " Number of Tokens: 25\n",
            " Tokens:\n",
            "['Ċ', 'def', 'Ġprime', '_', 'fact', 'ors', '(', 'n', '):', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġfactors', 'Ġ=', 'Ġ[]', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġdiv', 'is', 'or', 'Ġ=', 'Ġ2']\n",
            "\n",
            " Token IDs:\n",
            "[50118, 9232, 2654, 1215, 24905, 994, 1640, 282, 3256, 50118, 1437, 1437, 1437, 2433, 5457, 48081, 50118, 1437, 1437, 1437, 14445, 354, 368, 5457, 132]\n",
            "\n",
            " Sample 2 Chunked Code:\n",
            "    while n > 1:\n",
            "        while n // divisor == 0:\n",
            "            factors.append(divisor)\n",
            "            n /= divisor\n",
            "\n",
            " Number of Tokens: 63\n",
            " Tokens:\n",
            "['Ġ', 'Ġ', 'Ġ', 'Ġwhile', 'Ġn', 'Ġ>', 'Ġ1', ':', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġwhile', 'Ġn', 'Ġ//', 'Ġdiv', 'is', 'or', 'Ġ==', 'Ġ0', ':', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġfactors', '.', 'append', '(', 'div', 'is', 'or', ')', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġn', 'Ġ/', '=', 'Ġdiv', 'is', 'or']\n",
            "\n",
            " Token IDs:\n",
            "[1437, 1437, 1437, 150, 295, 8061, 112, 35, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 150, 295, 21277, 14445, 354, 368, 45994, 321, 35, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 2433, 4, 48696, 1640, 26037, 354, 368, 43, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 295, 1589, 5214, 14445, 354, 368]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def chunk_code_by_lines(code, chunk_size):\n",
        "    \"\"\"Splits a block of code into chunks of max `chunk_size` lines.\"\"\"\n",
        "    lines = code.split('\\n')\n",
        "    return ['\\n'.join(lines[i:i+chunk_size]) for i in range(0, len(lines), chunk_size)]\n",
        "\n",
        "# Parameters\n",
        "file_path = '/content/Cleaned_Regraded_Volunteering_Grader2(1).xlsx'     # Update with your actual file path\n",
        "code_column = 'Code_with_Error'               # Update with the name of your code column\n",
        "chunk_size = 10                    # Max lines per chunk\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Apply chunking\n",
        "chunked_data = []\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    code_chunks = chunk_code_by_lines(row[code_column], chunk_size)\n",
        "    for i, chunk in enumerate(code_chunks):\n",
        "        chunked_data.append({\n",
        "            'original_index': idx,\n",
        "            'chunk_number': i,\n",
        "            'code_chunk': chunk\n",
        "        })\n",
        "\n",
        "# Create a new DataFrame with the chunks\n",
        "chunked_df = pd.DataFrame(chunked_data)\n",
        "\n",
        "# Save or inspect\n",
        "chunked_df.to_csv('chunked_code_logic_dataset.csv', index=False)\n",
        "print(chunked_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0Spitq9jyqC",
        "outputId": "ba09a9fb-64fd-413e-b913-8dc0508749b7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   original_index  chunk_number  \\\n",
            "0               0             0   \n",
            "1               0             1   \n",
            "2               1             0   \n",
            "3               1             1   \n",
            "4               2             0   \n",
            "\n",
            "                                          code_chunk  \n",
            "0  def prime_factors(n):\\n    factors = []\\n    d...  \n",
            "1                                   number = 56\\n}\")  \n",
            "2  def prime_factors(n):\\n    factors = []\\n    d...  \n",
            "3                                   number = 56\\n}\")  \n",
            "4  def prime_factors(n):\\n    factors = []\\n    d...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/chunked_code_logic_dataset.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "k0sqpNYPl9vM",
        "outputId": "0abcf0b9-8cf4-482d-81f5-1c849d7423ca"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c16aa804-2a34-4f09-acff-dc465f258014\", \"chunked_code_logic_dataset.csv\", 383243)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizer\n",
        "import pandas as pd\n",
        "\n",
        "# Load CodeBERT tokenizer (same as RoBERTa-base for tokenization)\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "\n",
        "# Load sample code from Excel dataset\n",
        "df = pd.read_csv(\"/content/chunked_code_logic_dataset.csv\")\n",
        "code_column = \"code_chunk\"  # Adjust if needed\n",
        "sample_codes = df[code_column].dropna().head(2).tolist()  # Get first 2 code samples\n",
        "\n",
        "# Tokenize and compare\n",
        "for i, code in enumerate(sample_codes):\n",
        "    print(f\"\\n Sample {i+1} Chunked Code:\\n{code}\\n\")\n",
        "\n",
        "    tokens = tokenizer.tokenize(code)\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "    print(f\" Number of Tokens: {len(tokens)}\")\n",
        "    print(\" Tokens:\")\n",
        "    print(tokens)\n",
        "    print(\"\\n Token IDs:\")\n",
        "    print(token_ids)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfIh5QflgdGT",
        "outputId": "f5323b95-82de-48ee-b1b3-5a48b1d9f6fa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Sample 1 Chunked Code:\n",
            "def prime_factors(n):\n",
            "    factors = []\n",
            "    divisor = 2\n",
            "    while n > 1:\n",
            "        while n // divisor == 0:\n",
            "            factors.append(divisor)\n",
            "            n /= divisor\n",
            "        divisor += 2\n",
            "    return factors\n",
            "\n",
            "\n",
            " Number of Tokens: 108\n",
            " Tokens:\n",
            "['def', 'Ġprime', '_', 'fact', 'ors', '(', 'n', '):', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġfactors', 'Ġ=', 'Ġ[]', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġdiv', 'is', 'or', 'Ġ=', 'Ġ2', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġwhile', 'Ġn', 'Ġ>', 'Ġ1', ':', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġwhile', 'Ġn', 'Ġ//', 'Ġdiv', 'is', 'or', 'Ġ==', 'Ġ0', ':', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġfactors', '.', 'append', '(', 'div', 'is', 'or', ')', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġn', 'Ġ/', '=', 'Ġdiv', 'is', 'or', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġdiv', 'is', 'or', 'Ġ+=', 'Ġ2', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġreturn', 'Ġfactors', 'Ċ']\n",
            "\n",
            " Token IDs:\n",
            "[9232, 2654, 1215, 24905, 994, 1640, 282, 3256, 50118, 1437, 1437, 1437, 2433, 5457, 48081, 50118, 1437, 1437, 1437, 14445, 354, 368, 5457, 132, 50118, 1437, 1437, 1437, 150, 295, 8061, 112, 35, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 150, 295, 21277, 14445, 354, 368, 45994, 321, 35, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 2433, 4, 48696, 1640, 26037, 354, 368, 43, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 295, 1589, 5214, 14445, 354, 368, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 14445, 354, 368, 49371, 132, 50118, 1437, 1437, 1437, 671, 2433, 50118]\n",
            "\n",
            " Sample 2 Chunked Code:\n",
            "number = 56\n",
            "}\")\n",
            "\n",
            " Number of Tokens: 6\n",
            " Tokens:\n",
            "['number', 'Ġ=', 'Ġ56', 'Ċ', '}', '\")']\n",
            "\n",
            " Token IDs:\n",
            "[30695, 5457, 4772, 50118, 24303, 8070]\n"
          ]
        }
      ]
    }
  ]
}